stages:
  - package_build

variables:
  # The SRC_PATH is in the GOPATH of the builders which
  # currently is /go
  SRC_PATH: /go/src/github.com/DataDog/datadog-agent
  # Directory in which we execute the omnibus build.
  # For an unknown reason, it does not go well with
  # a ruby dependency if we build directly into $CI_PROJECT_DIR/.omnibus
  OMNIBUS_BASE_DIR: /.omnibus
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR: $CI_PROJECT_DIR/.omnibus/pkg/
  # Directory in which we execute the omnibus build for SUSE
  # as we want to separate the RPM built for this distro.
  OMNIBUS_BASE_DIR_SUSE: /.omnibus/suse
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR_SUSE: $CI_PROJECT_DIR/.omnibus/suse/pkg
  OMNIBUS_BASE_DIR_WIN: c:\omni-base\$CI_RUNNER_ID
  OMNIBUS_BASE_DIR_WIN_OMNIBUS: c:/omni-base/$CI_RUNNER_ID
  DD_AGENT_TESTING_DIR: $CI_PROJECT_DIR/test/kitchen
  STATIC_BINARIES_DIR: bin/static
  DOGSTATSD_BINARIES_DIR: bin/dogstatsd
  AGENT_BINARIES_DIR: bin/agent
  CLUSTER_AGENT_BINARIES_DIR: bin/datadog-cluster-agent
  DEB_S3_BUCKET: apt.datad0g.com
  RPM_S3_BUCKET: yum.datad0g.com
  WIN_S3_BUCKET: dd-agent-mstesting
  ANDROID_S3_BUCKET: dd-agent-androidtesting
  DEB_RPM_BUCKET_BRANCH: nightly  # branch of the DEB_S3_BUCKET and RPM_S3_BUCKET repos to release to, 'nightly' or 'beta'
  DEB_TESTING_S3_BUCKET: apttesting.datad0g.com
  RPM_TESTING_S3_BUCKET: yumtesting.datad0g.com
  WINDOWS_TESTING_S3_BUCKET: $WIN_S3_BUCKET/pipelines/$CI_PIPELINE_ID
  WINDOWS_BUILDS_S3_BUCKET: $WIN_S3_BUCKET/builds
  ANDROID_BUILDS_S3_BUCKET: $ANDROID_S3_BUCKET/builds
  DEB_RPM_TESTING_BUCKET_BRANCH: testing  # branch of the DEB_TESTING_S3_BUCKET and RPM_TESTING_S3_BUCKET repos to release to, 'testing'
  DD_REPO_BRANCH_NAME: $CI_COMMIT_REF_NAME
  S3_CP_OPTIONS: --only-show-errors --region us-east-1 --sse AES256
  S3_CP_CMD: aws s3 cp $S3_CP_OPTIONS
  S3_ARTEFACTS_URI: s3://dd-ci-artefacts-build-stable/$CI_PROJECT_NAME/$CI_PIPELINE_ID
  S3_OMNIBUS_CACHE_BUCKET: dd-ci-datadog-agent-omnibus-cache-build-stable
  S3_DSD6_URI: s3://dsd6-staging/linux
  RELEASE_VERSION: nightly
  DEBUG_BUILD: Debug


# Default before_script for all the jobs. If you create a new job and don't want this to execute
# you NEED to overwrite it.
before_script:
  - echo running default before_script
  - cd $SRC_PATH
  - pip install --upgrade --ignore-installed pip setuptools
  - pip install -r requirements.txt
  - inv -e deps

#
# Trigger conditions
#

# run job only when triggered by an external tool (ex: Jenkins). This is used
# for jobs that run both on nightlies and tags
.run_when_triggered: &run_when_triggered
  only:
    - triggers


# anchor to trigger test kitchen setup, run, and cleanup (so all stages
# are run if one stage is run).  Triggers as defined:
# - master
# - tags (a tagged build)
# - triggers (as above, when triggered by an external tool like jenkins)
# - web (when the build is triggered by a specific build request through the
#        web interface.  This way, if a kitchen run is desired on a specific branch,
#        it can be triggered by requesting a specific build)
#
.run_when_testkitchen_triggered: &run_when_testkitchen_triggered
  only:
    - master
    - tags
    - triggers
    - web

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION is NOT "nightly". In this setting we are building either a
# new tagged version of the agent (an RC for example). In both cases the
# artifacts should be uploaded to our staging repository.

.run_when_triggered_on_tag: &run_when_triggered_on_tag
  only:
    refs:
      - triggers
  except: # we have to use except since gitlab doens't handle '!=' operator
    variables:
      - $RELEASE_VERSION == "nightly"
      - $RELEASE_VERSION == "" # no  RELEASE_VERSION means a nightly build for omnibus

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION is "nightly". In this setting we build from master and update
# the nightly build for windows, linux and docker.

.run_when_triggered_on_nightly: &run_when_triggered_on_nightly
  only:
    refs:
      - triggers
    variables:
      - $RELEASE_VERSION == "nightly"

#
# Job conditions
#

# run job when building Datadog Cluster Agent release tag

.run_on_cluster_agent_tag: &run_on_cluster_agent_tag
  only:
    refs:
      - tags
    variables:
      - $CI_COMMIT_TAG =~ /^dca-([\d.-]|rc)+$/

# skip job when building Datadog Cluster Agent release tag

.skip_on_cluster_agent_tag: &skip_on_cluster_agent_tag
  except:
    refs:
      - tags
    variables:
      - $CI_COMMIT_TAG =~ /^dca-([\d.-]|rc)+$/

#
# source_test
#

#
# package_build



# build Agent package for deb-x64
agent_deb-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deb_x64:latest
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --base-dir $OMNIBUS_BASE_DIR --omnibus-s3-cache --log-level info
    - dpkg -c $OMNIBUS_BASE_DIR/pkg/datadog-agent*_amd64.deb
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-agent*_amd64.deb $S3_ARTEFACTS_URI/datadog-agent_amd64.deb
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-agent*_amd64.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR
